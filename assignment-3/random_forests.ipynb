{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assignment: Decision Trees and Random Forests",
   "id": "bf34b21e0182f2e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Setting Up the Data",
   "id": "330c770cd872b237"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From UCI Machine Learning Repository we first fetched the [**Phishing Websites**](https://archive.ics.uci.edu/dataset/327/phishing+websites) data set. ",
   "id": "f0772a454cb66fcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "  \n",
    "# fetch dataset \n",
    "phishing_websites = fetch_ucirepo(id=327) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = phishing_websites.data.features \n",
    "y = phishing_websites.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(phishing_websites.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(phishing_websites.variables) "
   ],
   "id": "27f9a2420c865b59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Business Understanding",
   "id": "97976a932cc9371b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The goal is to asses whether a website can be classified as phishing or legitimate based on website features using **Decision Tree** and **Random Forest**.\n",
    "\n",
    "Model performance is evaluated to determine if a reliable phishing prediction is feasible with the given data and models."
   ],
   "id": "9124974aa1e54d3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data Understanding",
   "id": "5825905745afa311"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inspect the data\n",
    "X.info()\n",
    "X.describe()\n",
    "\n",
    "# Display the targets\n",
    "print(\"\\nTarget value counts:\\n\" ,y.value_counts())\n",
    "\n",
    "# Display unique values for each feature\n",
    "print(\"\\nUnique values for each feature:\")\n",
    "for num, col in enumerate(X.columns):\n",
    "    unique_vals = sorted(int(x) for x in X[col].unique())\n",
    "    print(f\"{num} {col}: {unique_vals}\")"
   ],
   "id": "1a085beafcb98d60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The dataset contains 11,055 entries and 30 columns. Each row represents a website, and the columns represent different website-related features. The feature values are encoded as -1, 0, and 1, describing whether a website characteristic looks bad, suspicious, or normal.",
   "id": "c992e61d9a94373d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Preparation",
   "id": "195e8eea3ebf3c00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The dataset is complete and consistent. Features and Targets are separated. No additional preparation required.",
   "id": "e077bf16f21b612e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Modeling",
   "id": "bde6404e2ff9841"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data splitting\n",
    "The data is split into two sets. One for training and one for testing. \n",
    "* Training: 70%\n",
    "* Testing: 30%"
   ],
   "id": "b24a6380141f2b79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")"
   ],
   "id": "596d5a667094769e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base Random Forest\n",
    "First we create a base Random Forest model with default hyperparameters, we will use this as a reference point for later comparisons."
   ],
   "id": "88d65ae2b72b3bc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_samples=0.7,\n",
    "    max_features=0.75,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ],
   "id": "bb6a2e5fb09d59d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Random Forest Hyperparameter Tuning\n",
    "Next we perform hyperparameter tuning via grid search with cross-validation to find the best combination of hyperparameters for the model.\n",
    "\n",
    "This setup uses 5-fold cross-validation and 6 different hyperparameters (64 combinations), resulting in 320 model fits. The combination resulting in the highest mean cross-validation accuracy is selected as the final tuned model."
   ],
   "id": "b8aba6ad334054dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Try different hyperparameter combinations\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"max_depth\": [20, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [0.7, 0.75],\n",
    "    \"max_samples\": [0.7, 0.75]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Select the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)"
   ],
   "id": "c9866ce6cf958ab6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training model with max depth 3",
   "id": "a1af78c4cec4ef3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_3 = RandomForestClassifier(\n",
    "    max_depth=3,\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_3.fit(X_train, y_train)"
   ],
   "id": "d43c0ca99d0c0059"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Evaluation",
   "id": "dd0c8fd19fc2777a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluating the performance of both the base and tuned Random Forest models.",
   "id": "2a7ed8dc818104c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate the base Random Forest\n",
    "y_pred_base = rf.predict(X_test)\n",
    "print(\"Base Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
    "print(\"\\nBase Classification Report:\\n\", classification_report(y_test, y_pred_base))\n",
    "print(\"\\nBase Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_base))\n",
    "\n",
    "# Evaluate the tuned Random Forest\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "print(\"Tuned Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"\\nTuned Classification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"\\nTuned Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n",
    "\n",
    "# Evaluate max depth 3 Random Forest\n",
    "y_pred_3 = rf_3.predict(X_test)\n",
    "print(\"Max depth 3 Accuracy:\", accuracy_score(y_test, y_pred_3))\n",
    "print(\"\\nMax depth 3 Report:\\n\", classification_report(y_test, y_pred_3))\n",
    "print(\"\\nMax depth 3 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_3))"
   ],
   "id": "bf41492a38a840df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Deployment",
   "id": "ecea81b4465f75a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compared to similiar hyperparameters in the decision tree, the random forest displays only minor improvements accuracy.\n",
    "However it has much higher recall in recognising phishing sites, without adversely affecting its recall in terms of legitimate sites.\n",
    "It can also much more reliably recognise legitimate sites with 4 points higher precision with only a slight dip in precision in phishing sites.\n",
    "The model does show\n"
   ],
   "id": "b92017fac0e4c742"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
