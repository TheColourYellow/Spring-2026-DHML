{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Setting Up The Data",
   "id": "ef8540cbe2b6345f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pip install ucimlrepo",
   "id": "7845f9616376bd33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "df = breast_cancer_wisconsin_diagnostic.data.original \n",
    "  \n",
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) \n"
   ],
   "id": "359cdaaa1b3249e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Business Understanding",
   "id": "8f0a29f3d7184b24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Problem:** Predict if a breast cancer tumor is malignant or benign based on diagnostic measurements.  \n",
    "**Objective:** Learn to apply the kNN algorithm to classify tumors and evaluate performance."
   ],
   "id": "d3c216e232989c13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Data Understanding",
   "id": "229c6c8c9ef967f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.info()\n",
    "df.describe().T"
   ],
   "id": "7b334f5b5ae552eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataset contains 569 instances and 32 columns:\n",
    "- ID: Unique identifier\n",
    "- Diagnosis: Target variable (M = Malignant, B = Beningn)\n",
    "- 30 numeric features: measurements of breast tumors\n",
    "\n",
    "**Observations:**\n",
    "- No null values\n",
    "- Distribution: 212 malignant, 357 benign.\n",
    "- Values are not normalized"
   ],
   "id": "6af4c1fcec90a55e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Data Preparation",
   "id": "75e23241283babc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Drop ID column\n",
    "df = df.drop(columns=[\"ID\"])\n",
    "\n",
    "# Map diagnosis to binary values: Malignant = 1, Benign = 0\n",
    "df[\"Diagnosis\"] = df[\"Diagnosis\"].map({\"M\":1, \"B\":0})\n",
    "\n",
    "# Split features and target variable\n",
    "features = df.drop(columns=[\"Diagnosis\"])\n",
    "labels = df[\"Diagnosis\"]\n",
    "\n",
    "# Normalize features\n",
    "features = (features - features.mean()) / features.std()\n",
    "\n",
    "# Display summary statistics of features\n",
    "features.describe().T"
   ],
   "id": "a1116d5ca7a4b903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', \n",
    "            'concavity', 'concave_points', 'symmetry', 'fractal_dimension']\n",
    "\n",
    "for feature in features:\n",
    "    cols = [f\"{feature}1\", f\"{feature}2\", f\"{feature}3\"]\n",
    "    df_subset = df[cols].copy()\n",
    "    df_subset.columns = [f\"{feature.capitalize()}1\", f\"{feature.capitalize()}2\", f\"{feature.capitalize()}3\"]\n",
    "    \n",
    "    df_subset.plot(kind='hist', bins=30, alpha=0.5, figsize=(8,5),\n",
    "                   title=f\"Distribution of {feature.capitalize()}\")\n",
    "    plt.xlabel(feature.capitalize())\n",
    "    plt.show()\n"
   ],
   "id": "623562849ab013bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Modeling",
   "id": "8d3628b29a2b849b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data splitting\n",
    "The data is split into three sets using the hold-out validation technique:\n",
    "- Training Set: 60% of the data for training the classifier\n",
    "- Validation Set: 20% to select the best hyperparameter k value\n",
    "- Test Set: 20% to evaluate the final model performance\n",
    "\n",
    "Stratified sampling is used to maintain class distribution across all sets."
   ],
   "id": "7bb06a869d0b64c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ],
   "id": "a5e2aadfd036b20d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train.shape, X_val.shape, X_test.shape",
   "id": "5dd505ede210ef9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The training set contains 341 instances, the validation set 114 instances, and the test set 114 instances which confirms the 60-20-20 split.",
   "id": "1a65289cccc4b9c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "We will train kNN classifiers with different odd values of k (from 1 to 21) and evaluate their accuracy on the validation set to select the best model configuration."
   ],
   "id": "386101953abfb340"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "k_values = range(1, 22, 2)\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_val_pred = knn.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"k\": k,\n",
    "        \"Validation Accuracy\": val_accuracy\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(\"Validation Accuracy\", ascending=False)"
   ],
   "id": "de88999e3dd3c185"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The validation results indicate that multiple k values result in the same highest accuracy. The smallest k is selected to favor a simpler model.",
   "id": "f567529ebed2602c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_k = results_df.loc[results_df[\"Validation Accuracy\"].idxmax(), \"k\"]\n",
    "\n",
    "print(\"Best k =\", best_k)\n",
    "best_k"
   ],
   "id": "802de20bb928ad18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Analysis provides 2 as the most accurate k-value to use, however looking at the data every other k-value past 3, where it strangely slightly dips in accuracy, provides the same level of accuracy.\n",
    "Knowing the workings of k-value, where-in new datapoints are designated via \"polling\" based on the designation of its closest neighbouring points, choosing 5 as the k value seems most sensible, as this will not allow for creation of a stalemate in polling."
   ],
   "id": "25db04c130de3f82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Evaluation",
   "id": "a8fd52d57057195d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5)\n",
    "model.fit(features, labels)\n",
    "\n",
    "labels_pred = model.predict(features)\n",
    "cm = confusion_matrix(labels, labels_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"Benign\", \"Malignant\"])\n",
    "cmd.plot()"
   ],
   "id": "b86ff3ae3907f7bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One malignant tumor erroneously identified as benign and 10 benign tumors as malignant.\n",
   "id": "77da318c935f2b61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "accuracy = (356+202) / (569)\n",
    "precision_be = (356) / (356 + 10)\n",
    "precision_mal = (202) / (202+1)\n",
    "recall_be = 356 / 357\n",
    "recall_mal = 202 / 212\n",
    "\n",
    "print(accuracy)\n",
    "print(precision_be)\n",
    "print(precision_mal)\n",
    "print(recall_be)\n",
    "print(recall_mal)"
   ],
   "id": "b174b38fd89ebfab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Accuracy of the model is 356 correctly identified benign tumors and 202 malignant tumors, divided by the full amount in the dataset: 569.\n",
    "This rounds to 98,1% accuracy.\n",
    "Precision for benign detection is the correctly identified 356 tumors divided by that amount in addition with the incorrectly benign attributed malignant tumors, which rounds to 97,3%\n",
    "Precision for the malignat tumors following same principle rounds to 99,5%\n",
    "Recall for the benign tumors is the correctly identified 356 tumors divided by all the designated bening tumors in the dataset which rounds to 99,7%\n",
    "Recall for the malignant tumors rounds to 95,3%"
   ],
   "id": "79b26aec9bb7e759"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Deployment",
   "id": "ac46c50006c1eb43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The completed model displays some potential in being able to detect nature of a tumor by its physical dimensions.\n",
    "However the model seems to have a slight bias towards designating its inputs towards benign.\n",
    "Both recall for malignant tumors and precision in determing benign tumors are considerably lower when compared to other statistics in the model.\n",
    "The dataset provided is substantive enough in quantity that we can consider this as statistically significant, and thus the model is not suited"
   ],
   "id": "243d008c788055fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
